# Bernard Williams, “Deciding to believe,” in *Problems of the Self* (Cambridge: Cambridge University Press, 1973): 136-151.

Introductory material:

1. Williams will discuss ordinary beliefs (e.g., that it is raining) rather
   than religious or moral beliefs.
2. Williams will discuss beliefs as a psychological state: i.e., people
   believing things. He won’t focus on belief as what a person believes nor on
   belief as a proposition that many people might believe.
3. Williams cares most of all about “the relations between belief and decision
   and certain puzzles that arise about the relation between these two ideas”
   (136).

Five characteristics of belief, as Williams sees it:

1. Beliefs aim at truth. This means: (i) we assess beliefs as true or false,
   though we don’t assess all psychological states or dispositions in this way;
   further, if a person realizes that a belief of theirs is false, they give up
   the belief (me: is this true?); (ii) to believe that *p* is to believe that
   *p* is true; (iii) as a result of the first two points, to say ‘I believe
   that *p*’ is already a claim that *p* is the case; if we say ‘I believe that
   *p*,’ we *eo ipso* make a claim that *p* is true; Williams connects this with
   the paradox that G. E. Moore discusses: ‘I believe that it is raining, but it
   is not raining’ is a paradox but not a formal self-contradiction; (if it were
   then every sentence of the type ‘*x* believes that *p*, but *p* is false’
   would be a self-contradiction, and that’s obviously wrong); only in the first
   person is there a paradox, and Williams takes this to show that stating
   a belief that *p* makes a claim; (*NB*: this alone gives skeptics good reason
   to avoid beliefs and assertions of belief!);
2. The simplest, most direct expression of a belief that *p* is the assertion
   *p*. That is, the simples way to assert your belief that it is day is simply
   to say “It is day.” To say “I believe that it is day” is to assert something
   else or something more than simply your belief that it is day. As Williams
   points out, the most common use of “I believe that *p*” is to qualify or
   weaken an assertion. He imagines a situation where someone asks for
   directions, and he compares two responses: (i) it’s three blocks down and on
   the right versus (ii) I believe that it’s three blocks down and on the right.
   (As a side note, Williams compares the relationship of “*p*” and “I believe
   that *p*” to “I will do so and so” versus “I intend to do so and so.” As
   a further aside, Williams notes that we ascribe beliefs to non-language-using
   animals and that this is fine. In Williams’s view, the ascription of belief
   is “somewhat impoverished” or conventional.)
3. Even though the most direct way to express a belief is an assertion, an
   assertion of *p* is neither a necessary nor a sufficient condition of having
   the belief that *p*. Assertion is not necessary since a person can have
   beliefs that they keep to themselves. Assertion is not sufficient since
   people can make insincere assertions.
4. Factual beliefs can be based on evidence. As Williams says, this is true in
   more than one sense. On the one hand, in an impersonal sense, we might say
   that the belief that *p* is based on evidence *q*. In such a case, we’re not
   saying that anyone necessarily believes *p* because of *q*. (Instead, we seem
   to be saying that it is rational to believe *p* because of *q*.) On the other
   hand, actual individuals may believe *p* because *q*. In such cases, the
   person believes *q* and that belief helps to explain the person’s additional
   belief *p*. In many cases, if the person stops believing *q*, they would also
   stop believing *p*. Where the person’s beliefs are rational, the person (and
   others) can say “*p* because *q*,” but if the person just happens to believe
   both *p* and *q* for irrational reasons or for no good reasons at all, then
   the person cannot “rightly” say “*p* because *q*.” Williams stresses that
   even when the connection between beliefs is rational, it is no less causal
   for that. (Williams digresses to talk about human perception here. He argues
   that in perception, we have an example of beliefs that are *based* in some
   sense, but not based on evidence. He also argues that we can understand what
   happens in human, as opposed to non-human animal, perception specially
   because we have a “shared experience, having a shared language and having
   a common perceived environment which we can know to be such” because “we
   share concepts which simultaneously enable us to express our beliefs about
   our invironment, to describe that environment, and to describe other people’s
   perception of the environment” (144).)

   According to Williams, a machine that could satisfy (1), (2), and (4) above
   would not manifest belief. Unless the machine could make insincere assertions
   (condition (3)), then it would not have beliefs but only some lesser state.
   In fact, Williams continues, if (3) is not satisfied, then even the other
   features of the machine must be very impoverished. For example, any assertion
   from someone or something that cannot lie is an assertion only in an
   impoverished sense.

   Williams argues that we can attribute at least some simple forms of knowledge
   to such a machine, but we cannot attribute anything but a very impoverished
   sense of belief. As such, he thinks that this shows that we are wrong to
   assume “that knowledge must be at least as grad as belief, that what
   knowledge is, is belief plus quite a lot” (146). Williams believes, on the
   contrary, that a far more primitive machine might have knowledge than one
   that had proper beliefs. For Williams, belief only enters with the will. Only
   a creature with a will can choose to reveal or not, can be insincere or
   choose to keep quiet.

   All of which shows that there is *a* relation of belief and decision.
   Decision enters at the point of choosing whether or not to reveal what one
   thinks. But there is a further question, namely can one decide whether or not
   to believe that *p*?

   Hume thought of belief “as a passive phenomenon, something that happens to
   us,” but Williams criticizes Hume for considering the passivity of belief
   a contingent or accidental matter. However, Williams argues that some
   features of our behavior and mental lives may be only contingently related to
   our wills, but belief isn’t one of them. As a counterexample, Williams refers
   to blushing at will.

   Why not? Why is the connection between belief and will not contingent?
   Williams locates the answer, partly, in “the characteristic of beliefs that
   they aim at truth” (148). A second reason, Williams argues, is that if people
   can believe at will, then the notion of empirical, perceptual belief is
   undone. Why not? Because “there would be no regular connexion between the
   environment, the perceptions” and what the person ends up believing (149).

   Williams finally considers indirect examples of “deciding to believe.” If,
   for example, I could go to a hypnotist in order to get myself to believe that
   *p*, how does this count as “deciding to believe”? Williams distinguishes
   between two kinds of “wanting to believe”: one is truth-centered and the
   other is non-truth-centered. For the truth-centered motive, a person wants
   *the belief to be true*, not merely that they believe it. For the
   non-truth-centered motive, a person wants to believe even despite the truth
   of things. According to Williams, there may be non-truth-centered desires to
   believe, but if so, they are “very deeply irrational.”

   Williams concludes by making a few brief questions about why we find a desire
   to believe what we know is false to irrational and why we object to such
   a behavior so strongly. He wonders, first, whether the desire to believe what
   one knows to be false is so different from a desire to forget what one knows
   is true? (He answers that there is a genuine asymmetry between belief and
   knowledge in this area. Every belief aims at truth, but knowledge, as such,
   does not aim at omniscience.) Second, Williams suggests that such a desire to
   believe what is false is dangerous because “there is no end to the amount you
   have to pull down” (151).


